# -*- coding: utf-8 -*-
"""Q1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f8O9iTUx1w5ti62FxVKEfOJXXILH7hWR
"""

'''
Q1: Generate Data for Linear Regression and the Estimate the error
'''
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

class LinearRegressionDataGenerator:
    """
    Generates data
    """
    def __init__(self, N, D, w, noise_amount=0.1):
        self.N = N
        self.D = D
        self.w = w
        self.noise_amount = noise_amount
        self.X = None
        self.y = None

    def generate_linear_regression_data(self):
        """
        Generates the feature matrix X and the label vector y.
        """
        self.generate_X()
        self.calculate_y()
        return self.X, self.y, self.w

    def generate_X(self):
        self.X = np.random.randn(self.N, self.D)

    def calculate_y(self):
        self.y = np.dot(self.X, self.w)
        # Gaussian noise
        noise = np.random.normal(0, self.noise_amount, self.N)
        self.y += noise

        self.y = self.y.reshape(-1, 1)


class LinearRegressionAnalyzer:
    """
    Performs linear regression using Gradient Descent and analyzes its performance.
    """
    def __init__(self):
        pass

    def compute_wstar(self, X, y):
        X_aug = np.c_[np.ones((X.shape[0], 1)), X]
        w_star = np.linalg.inv(X_aug.T @ X_aug) @ X_aug.T @ y

        return w_star

    def calculate_estimation_error(self, w, w_star):
        mse = np.mean((w - w_star)**2)

        return {"mse": mse}

    def gradient_descent_analysis(self, X, y, theta, eta):
      theta_path = []

      n_iterations = 100
      m = np.size(y)

      X_c = np.c_[np.ones((m,1)), X]

      for iteration in range(n_iterations):
        gradients = 2/m * X_c.T @ (X_c @ theta - y)
        theta = theta - eta * gradients
        theta_path.append(theta.flatten())

      return theta_path

    def sgd_analysis(self, X, y, theta, eta):
      theta_path = []

      n_iterations = 100
      m = np.size(y)

      X_c = np.c_[np.ones((m,1)), X]

      for iteration in range(n_iterations):
        shuffle_idx = np.random.permutation(m)
        X_c_shuffle = X_c[shuffle_idx,:]
        y_shuffle = y[shuffle_idx]
        for i in range(m):
          X_c_one = X_c_shuffle[i:i+1, :]
          y_one = y_shuffle[i]

          gradients = 2 * X_c_one.T @ (X_c_one @ theta - y_one)
          theta = theta - eta * gradients

        theta_path.append(theta.flatten())

      return theta_path

    def mgd_analysis(self, X, y, theta, eta):
      theta_path = []

      n_iterations = 100
      m = np.size(y)
      mb_size = 10

      X_c = np.c_[np.ones((m,1)), X]

      for iteration in range(n_iterations):
        shuffle_idx = np.random.permutation(m)
        X_c_shuffle = X_c[shuffle_idx,:]
        y_shuffle = y[shuffle_idx]
        for i in range(0, m, mb_size):
          X_c_one = X_c_shuffle[i:i+mb_size, :]
          y_one = y_shuffle[i:i+mb_size]

          gradients = 2/mb_size * X_c_one.T @ (X_c_one @ theta - y_one)
          theta = theta - eta * gradients

        theta_path.append(theta.flatten())

      return theta_path

if __name__ == "__main__":
    print("**********************************************************************")
    print("Q1 ...")
    print("Step 1- Generating Data ...")

    # parameters for data generation
    N_q1 = 1000  # N >= 1000
    D_q1 = 4   # D >= 4
    w_q1 = np.array([1.5, 2, 3.5, 4])
    noise_q1 = True
    noise_amount_q1 = 0.1

    data_gen = LinearRegressionDataGenerator(
        N= N_q1,
        D= D_q1,
        w= w_q1,
        noise_amount= noise_amount_q1
        )

    X, y, true_w = data_gen.generate_linear_regression_data()
    # X, y, true_w = data_gen.generate_linear_regression_data(x_distribution='uniform', x_kwargs={'low': -2, 'high': 2})

    print("Shape of generated X:", X.shape)
    print("Shape of generated y:", y.shape)
    print("True weights used:", true_w)
    print("First 3 samples of X:\n", X[:3])
    print("First 3 labels of y:\n", y[:3])
    print("**********************************************************************")

    # Perform Analyses on generated data and the true weights
    print("Step 2- Perform Analyses on generated data ...")
    analyzer = LinearRegressionAnalyzer()
    true_weights = true_w.reshape(-1, 1)
    X2 = X
    y2 = y
    n_iterations = 100
    theta = np.random.randn(X2.shape[1]+1,1)  # random initialization
    #theta = np.zeros((X2.shape[1]+1, 1))  # zero initialization
    #theta = np.random.uniform(low=-1, high=1, size=(X2.shape[1]+1, 1))  # uniform random initialization
    results = {}

    # Q1-1 Regression Test
    print("Regression Analysis ...")
    estimated_weights = analyzer.compute_wstar(X2, y2)
    if estimated_weights is not None:
        print("True Weights:\n", true_weights)
        print("Estimated Weights:\n", estimated_weights[1:])
        estimation_errors = analyzer.calculate_estimation_error(true_weights, estimated_weights[:-1].reshape(-1))
        print("\nEstimation Errors:")
        print(f"Mean Squared Error (MSE): {estimation_errors['mse']:.4f}")

    # Q1-2 gradient descent
    print("Gradient Descent Analysis ...")
    theta_path_gd = np.array(analyzer.gradient_descent_analysis(X2, y2, theta, eta=0.3))
    theta_path_sgd = np.array(analyzer.sgd_analysis( X2, y2, theta, eta=0.05))
    theta_path_mgd = np.array(analyzer.mgd_analysis( X2, y2, theta, eta=0.3))

    pca = PCA(n_components=2)
    theta_path_gd_2d = pca.fit_transform(theta_path_gd)
    theta_path_sgd_2d = pca.fit_transform(theta_path_sgd)
    theta_path_mgd_2d = pca.fit_transform(theta_path_mgd)

    plt.plot(theta_path_gd_2d[:,0], theta_path_gd_2d[:,1],'b-o', label='GD_path')
    plt.plot(theta_path_sgd_2d[:,0], theta_path_sgd_2d[:,1], 'r--', label='SGD_path')
    plt.plot(theta_path_mgd_2d[:,0],theta_path_mgd_2d[:,1], 'g-x', label='MGD_path')

    plt.legend()
    plt.show()